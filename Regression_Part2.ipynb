{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression_Part2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "MzmEcNHzuBI3",
        "DIlzJbCpmo0R",
        "rY_DT_ZrIiYC"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkjubran/MachineLearningNotebooks/blob/master/Regression_Part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzmEcNHzuBI3",
        "colab_type": "text"
      },
      "source": [
        "# Clone the Source GitHub Reporsitory \n",
        "We need to clone some source files to be used throughtout this tutorial from a GitHub reprository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmP4GrRNudXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./MachineLearning\n",
        "!git clone https://github.com/mkjubran/MachineLearning.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIlzJbCpmo0R",
        "colab_type": "text"
      },
      "source": [
        "# One Hot Encoding\n",
        "**Introduction**\n",
        "\n",
        "In this section, we will apply multiple leaner regression to a categorical data. \n",
        "\n",
        "We will be using the **One hot encoding** to convert nominal categorical variables into a form that could be provided to ML algorithms for linear regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeQ0wuIc1AHR",
        "colab_type": "text"
      },
      "source": [
        "**Theory** \\\\\n",
        "\n",
        "One hot encoding is a process by which nominal categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction.[1]\n",
        "\n",
        "Say suppose the dataset is as follows:\n",
        "\n",
        "City | Area| Price\n",
        "--- | --- | ---\n",
        "Jerusalem | 160 | 550000\n",
        "Jerusalem | 200 | 600000\n",
        "Jerusalem | 250 | 620000\n",
        "Ramallah | 160 | 200000\n",
        "Ramallah | 200 | 220000\n",
        "Ramallah | 240 | 300000\n",
        "Nablus | 160 | 150000\n",
        "Nablus | 230 | 180000\n",
        "Bethlehem | 160 | 160000\n",
        "Bethlehem | 210 | 180000\n",
        "\n",
        "\n",
        "We need to encode the names of the cities before passing this data into a machine learning model. This can be achieved through integer encoding as follows:\n",
        "\n",
        "City | Code | Area| Price\n",
        "--- | --- | --- | ---\n",
        "Jerusalem |0| 160 | 550000\n",
        "Jerusalem |0| 200 | 600000\n",
        "Jerusalem |0| 250 | 620000\n",
        "Ramallah  |1| 160 | 200000\n",
        "Ramallah  |1| 200 | 220000\n",
        "Ramallah  |1| 240 | 300000\n",
        "Nablus    |2| 160 | 150000\n",
        "Nablus    |2| 230 | 180000\n",
        "Bethlehem |3| 160 | 160000\n",
        "Bethlehem |3| 210 | 180000\n",
        "\n",
        "\n",
        "However, Ml might understand that Nablus is double Ramallah or Bethlehem is triple of Ramallah. But this categorical variable is not nominal (values don't exhibit any order as compared to ordinal variables) . so instead of this, we use **one hot coding** as follows:\n",
        "\n",
        "City | Jerusalem | Ramallah | Nablus| Bethlehem | Area| Price\n",
        "--- | --- | --- | --- | --- | --- | ---\n",
        "Jerusalem |1|0|0|0| 160 | 550000\n",
        "Jerusalem |1|0|0|0| 200 | 600000\n",
        "Jerusalem |1|0|0|0| 250 | 620000\n",
        "Ramallah  |0|1|0|0| 160 | 200000\n",
        "Ramallah  |0|1|0|0| 200 | 220000\n",
        "Ramallah  |0|1|0|0| 240 | 300000\n",
        "Nablus    |0|0|1|0| 160 | 150000\n",
        "Nablus    |0|0|1|0| 230 | 180000\n",
        "Bethlehem |0|0|0|1| 160 | 160000\n",
        "Bethlehem |0|0|0|1| 210 | 180000\n",
        "\n",
        "As can be seen, four independent variables (dummy variables) are created; Jerusalem, Ramallah, Nablus, and Bethlehem. Each of these dummy variables encodes its city by \"1\" otherwise it is \"0\". \n",
        "\n",
        "Before passing this table to the ML, we need to remove one of the city columns because it is not needed and also cause what is called **Dummy variable trap**$^{[2]}$; say we remove the dummy variable Ramallah, so if none of the other dummy variables (Jerusalem, Nablus, and  Bethlehem) is \"1\" then the ML learn it is Ramallah. The Dummy variable trap occurs when one dummy variable can be predicted using the other dummy variables. Reducing the dimensionality of the dataset also reduces the complexity and time of training the model. To read further about one hot coding you may refer to [1].\n",
        "\n",
        "[1] https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f\n",
        "[2] https://analyticstraining.com/understanding-dummy-variable-traps-regression/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RSwASngm9_9",
        "colab_type": "text"
      },
      "source": [
        "**Implementation**\n",
        "\n",
        "Read the input data from a csv file called \"homeprices_OHE.csv\" \\\\\n",
        "To read the data in the file, we will be using the pandas library (https://pandas.pydata.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQX2iq_fnJOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"./MachineLearning/1_Regression/homeprices_OHE.csv\")\n",
        "print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJA9kY1o6_lr",
        "colab_type": "text"
      },
      "source": [
        "As can be seen, one of the fields (city) contains nominal categorical variable. Thus we need to encode this field into numeric values using one-hot coding. We wil use the pd.get_dummies(df.city) method as"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryh3BJOV7eo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dm = pd.get_dummies(df.city)\n",
        "dm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39M2I3LU70dB",
        "colab_type": "text"
      },
      "source": [
        "After executing the above command we get a table with a code per city. Now we need to concatenate these rows to the original (df) dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtqBhjVN8Hgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_merge = pd.concat([df,dm],axis='columns')\n",
        "print(df_merge)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HHv5Gko8_20",
        "colab_type": "text"
      },
      "source": [
        "Now we need to get the multiple regression model. Note we pass the area and the three city dummy variables to train the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBkR7WTW9T7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "regm = linear_model.LinearRegression()\n",
        "regm.fit(df_merge[['area','Bethlehem','Jerusalem','Nablus']],df_merge.price)\n",
        "print(regm.coef_) ## print the coefficients\n",
        "print(regm.intercept_) ## print the intercept"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg0bQjS5CMlB",
        "colab_type": "text"
      },
      "source": [
        "Alternatively, we could clean the data frame by dropping the not needed fields from the data frame and then define the inout variables to the modelas "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCfpxkOSCuRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x= df_merge.drop(['Ramallah','city','price'],axis=1)\n",
        "print(x)\n",
        "y = df_merge.price\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eXLcFhJE1DU",
        "colab_type": "text"
      },
      "source": [
        "To train the model using x and y:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaa_QikPEzwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regm.fit(x,y)\n",
        "print(regm.coef_) ## print the coefficients\n",
        "print(regm.intercept_) ## print the intercept"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd0a13CuAMmf",
        "colab_type": "text"
      },
      "source": [
        "The model is now ready. To estimate the price of a new house in Ramallah with an area of 190 $m^2$, we apply it to the model as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuvM1TH8Anv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regm.predict([[190,0,0,0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV6Pc0FJL7AG",
        "colab_type": "text"
      },
      "source": [
        "The price of a house with 190 m^2 in Ramallah is about $232112. Let us next compare the prices of houses of the same size (area) in different cities. Use the city code based on the one hot coding shwon in output cell [37]. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fv4n1EhxMVK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_new=[[190,1,0,0],[190,0,1,0],[190,0,0,1],[190,0,0,0]]\n",
        "regm.predict(x_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sio0MGhXM5KO",
        "colab_type": "text"
      },
      "source": [
        "So the prices of houses with an area of 190 $m^2$ is as follows:\n",
        "\n",
        "City | Price\n",
        "--- | ---\n",
        "Bethlehem | 173943.76899694 \n",
        "Jerusalem | 579483.28267475\n",
        "Nablus | 161056.23100302\n",
        "Ramallah | 232112.46200606"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggh_Kpl9j9dr",
        "colab_type": "text"
      },
      "source": [
        "What about the accuracy of the model. We can view the accuracy of the model by printing the score as"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxujdNZDkIvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regm.score(x,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWJlXJcokudK",
        "colab_type": "text"
      },
      "source": [
        "The accuracy of the model is about $99.403\\%$. This is called the training accuracy because the data used for training is used to computed the model accuracy. Having high training accuracy means the model fitted the training data very well and the relationship of the training data is linear. However, we need to measure the accuracy of the model to predict the prices of new data not used for training. This will be discussed in the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rFQOBBCtqlE",
        "colab_type": "text"
      },
      "source": [
        "**Exercise**\n",
        "\n",
        "Use multiple linear regression to estimate the prices of the following cars:\n",
        "\n",
        "Specifications | Car #1 | Car #2 | Car #3\n",
        "-- | --- | --- | ---\n",
        "Make    |  BMW | Audi | Nissan\n",
        "Model    | 1 Series M | 100 | 370z\n",
        "Year      |      2011 | 1992 | 2106\n",
        "Engine Fuel Type|  premium unleaded (required) | regular unleaded | premium unleaded (required)\n",
        "Engine HP        |   335 |172 | 332\n",
        "Engine Cylinders  |   6 | 6 | 6\n",
        "Transmission Type  |   MANUAL | MANUAL | MANUAL\n",
        "Driven_Wheels      |  rear wheel drive | all wheel drive | rear wheel drive\n",
        "Number of Doors    |    2 | 4 | 2\n",
        "Market Category    |  Factory Tuner,Luxury,High-Performance | Luxury | High-Performance\n",
        "Vehicle Size       |   Compact | Midsize | Compact\n",
        "Vehicle Style      |    Coupe | Sedan | Coupe\n",
        "highway MPG        |     26 | 21 | 26\n",
        "city mpg           |     19 | 16 | 18\n",
        "Popularity         |   3916 | 3105 | 2009\n",
        "\n",
        "You may use a subset of the car features to train and predict prices. We will use the data set in the 'CarPrices.csv' file in the Github repository to train the model. This data set is downloaded from kaggle. $^{[1]}$ \n",
        "\n",
        "\n",
        "[1] https://www.kaggle.com/CooperUnion/cardataset/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtH_ZryIZOGc",
        "colab_type": "text"
      },
      "source": [
        "To read and view specific row of the data set, use the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ3KaBA0UvWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df_cars = pd.read_csv(\"./MachineLearning/1_Regression/carsdataset.csv\")\n",
        "row=100\n",
        "print(df_cars.loc[row,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY_DT_ZrIiYC",
        "colab_type": "text"
      },
      "source": [
        "# Model Accuracy\n",
        "\n",
        "In this section, we will learn how to measure the accuracy of a model. This requires splitting the available dataset into a training dataset and testing dataset. The training dataset will be used to derive the coefficients of the model. whereas the testing dataset will be used to measure the model accuracy which is sometimes referred to as testing accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTjGIsgEMl1l",
        "colab_type": "text"
      },
      "source": [
        "In this section, we will use part of the cars dataset used in the exercise above. This dataset is stored in the 'carsdataset_short.csv' in the repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZJ5BZRTNFXi",
        "colab_type": "text"
      },
      "source": [
        "To load the dataset we will use the panda library as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0SRCu49NMxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "cars = pd.read_csv(\"./MachineLearning/1_Regression/carsdataset_short.csv\")\n",
        "print(cars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51swnXPKQVvL",
        "colab_type": "text"
      },
      "source": [
        "Now we will use one hot coding to represent the car make as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HVX9z_jQhEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CarMake = pd.get_dummies(cars.Make)\n",
        "cars_merge = pd.concat([cars, CarMake], axis=1)\n",
        "x = cars_merge.drop(['Make','price','Mercedes-Benz'],axis=1)\n",
        "y = cars_merge.price\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h5eUBGBP1Xf",
        "colab_type": "text"
      },
      "source": [
        "Now, we need to split the datset into training and testing datsets. We will use 80% of the dataset for training and the rest will be used for testing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCmJEuybQFYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n",
        "print(len(x))\n",
        "print(len(x_train))\n",
        "print(len(x_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkZNw0hfTOnV",
        "colab_type": "text"
      },
      "source": [
        "next we will train the linear regresison model using the training dataset as"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmM1vi8NTV38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "regm = linear_model.LinearRegression()\n",
        "regm.fit(x_train,y_train)\n",
        "print(regm.coef_) ## print the coefficients\n",
        "print(regm.intercept_) ## print the intercept"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIE3594bT8LI",
        "colab_type": "text"
      },
      "source": [
        "We will use the model now to predict the prices of the test datset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEBluiFpUJzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "price_test = regm.predict(x_test)\n",
        "print(price_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdc7rVxNjyRl",
        "colab_type": "text"
      },
      "source": [
        "To combine the actual prices of the test data sets and the predicted prices for observation use the following "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlzTMWN-jzGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_pred = pd.DataFrame.copy(y_test)\n",
        "y_test_pred = y_test_pred.to_frame()\n",
        "y_test_pred['pprice'] = price_test\n",
        "y_test_pred['difference'] = y_test_pred['price'] - y_test_pred['pprice']\n",
        "print(y_test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yeL9tHUUZyx",
        "colab_type": "text"
      },
      "source": [
        "The model accuracy can be obtained as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJcak-QoUmbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training accuracy\n",
        "Acc_train = regm.score(x_train,y_train)\n",
        "print(Acc_train)\n",
        "#testing accuracy\n",
        "Acc_test = regm.score(x_test,y_test)\n",
        "print(Acc_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCcKv8lxVCbB",
        "colab_type": "text"
      },
      "source": [
        "As expected, the training accuracy is greater than the testing accuracy. A high training accuracy means that the model fits very well hr training data and a high testing accuracy means that the model can be generalized to other samples or datasets."
      ]
    }
  ]
}