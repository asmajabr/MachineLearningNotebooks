{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KMeansClustering.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "DIlzJbCpmo0R"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkjubran/MachineLearningNotebooks/blob/master/KMeansClustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzmEcNHzuBI3",
        "colab_type": "text"
      },
      "source": [
        "# Clone the Source GitHub Reporsitory \n",
        "We need to clone some source files to be used throughtout this tutorial from a GitHub reprository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmP4GrRNudXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./MachineLearning\n",
        "!git clone https://github.com/mkjubran/MachineLearning.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge4LeJuiweBs",
        "colab_type": "text"
      },
      "source": [
        "(Optional) You may also disable future warning through running the following code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzzwDVhjwbt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIlzJbCpmo0R",
        "colab_type": "text"
      },
      "source": [
        "# K-Means Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrMDfwQQzBEn",
        "colab_type": "text"
      },
      "source": [
        "**Readings and Resources**\n",
        "\n",
        "1- https://towardsdatascience.com/k-means-clustering-algorithm-applications-evaluation-methods-and-drawbacks-aa03e644b48a\n",
        "\n",
        "2- https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1\n",
        "\n",
        "3- https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-k-means-clustering/\n",
        "\n",
        "4- https://towardsdatascience.com/k-means-clustering-from-a-to-z-f6242a314e9a\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOQvdG9QW1Yv",
        "colab_type": "text"
      },
      "source": [
        "# Case #1: Mall Customers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7ietEiOzhNl",
        "colab_type": "text"
      },
      "source": [
        "In this section, we will use k-means clustering to categories a mall customers based on their annual income and spending score (Spending Score is something you assign to the customer based on your defined parameters like customer behavior and purchasing data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RSwASngm9_9",
        "colab_type": "text"
      },
      "source": [
        "**Implementation**\n",
        "\n",
        "Read the input data about mall customers which includes annual incomde (number of study hours and exam pass or fail) from the csv file (Mall_Customers_short.csv) file. Use the pandas library (https://pandas.pydata.org/) to read the data from the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQX2iq_fnJOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"./MachineLearning/7_kmeans/Mall_Customers_short.csv\")\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e54VxpoB_aB9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "To get some information about the read dataset including parameters and type of fields and features use the pandas info method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ3EWqs8_bUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUwDBB-Z_eAH",
        "colab_type": "text"
      },
      "source": [
        "To get some information about the read dataset including parameters and type of fields and features use the pandas info method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FryKIhX_htO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(df['Annual Income'],df['Spending Score'],color = 'red', marker = '+')\n",
        "plt.xlabel('Annual Income')\n",
        "plt.ylabel('Spending Score')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39M2I3LU70dB",
        "colab_type": "text"
      },
      "source": [
        "As can be seen, the mall customers can be classified into 4 clusters. i.e visually, k should be 4 in k-means clustering algorithm.\n",
        "\n",
        "Let us apply the k-means clustering to this dataset, we will use the "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOSm3Wbnjo4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "km = KMeans(n_clusters=4)\n",
        "km.fit(df[['Annual Income','Spending Score']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDqVuQboCwPG",
        "colab_type": "text"
      },
      "source": [
        "To determine the cluster of each point, use the following code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHr2piSzCd0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cluster = km.predict(df[['Annual Income','Spending Score']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMbrjUFTC2_u",
        "colab_type": "text"
      },
      "source": [
        "Let us add the cluster array to the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPUfBVYyC__a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['cluster'] = cluster\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEQAKY8qDXhw",
        "colab_type": "text"
      },
      "source": [
        "Let us plot the points (features) using scatter plot but with different colors (based on their clusters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M053z1yuDi2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_0 = df[df['cluster'] == 0] \n",
        "df_1 = df[df['cluster'] == 1] \n",
        "df_2 = df[df['cluster'] == 2] \n",
        "df_3 = df[df['cluster'] == 3]\n",
        "plt.scatter(df_0['Annual Income'],df_0['Spending Score'],color = 'red', label = 'cluster 0')\n",
        "plt.scatter(df_1['Annual Income'],df_1['Spending Score'],color = 'blue', label = 'cluster 0')\n",
        "plt.scatter(df_2['Annual Income'],df_2['Spending Score'],color = 'green', label = 'cluster 0')\n",
        "plt.scatter(df_3['Annual Income'],df_3['Spending Score'],color = 'purple', label = 'cluster 0')\n",
        "plt.xlabel('Annual Income')\n",
        "plt.ylabel('Spending Score')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rJcVSVxkMPU",
        "colab_type": "text"
      },
      "source": [
        "**Is this what you expected?** \n",
        "\n",
        "The customers are clustered (classified) based on their **Annual Income** without considering the **Spending Score**. This is becuse of the scale of the features. The range of annual income is much higher (in 1000 units) as compared to Spending Score (0 - 100). To deal with this, we need to scale features as we did in a previous tutorial. However, this time we will use the MinMaxScaler method in sklearn library. We will first scale the **Annual Income** as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDtE8Sr4lG-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(df[['Annual Income']])\n",
        "print('scaler.min_ = {}'.format(scaler.min_)) #Per feature adjustment for minimum. Equivalent to min - X.min(axis=0) * self.scale_\n",
        "print('scaler.scale_ = {}'.format(scaler.scale_)) #Per feature relative scaling of the data. Equivalent to (max - min) / (X.max(axis=0) - X.min(axis=0))\n",
        "print('scaler.data_range_ = {}'.format(scaler.data_range_)) #Per feature range (data_max_ - data_min_) seen in the data\n",
        "df['Scaled Annual Income'] = scaler.transform(df[['Annual Income']])\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EZjy7ssKzTo",
        "colab_type": "text"
      },
      "source": [
        "Now, we will scale the **Spending Score** as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlXV04M_Kz6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler.fit(df[['Spending Score']])\n",
        "print('scaler.min_ = {}'.format(scaler.min_)) #Per feature adjustment for minimum. Equivalent to min - X.min(axis=0) * self.scale_\n",
        "print('scaler.scale_ = {}'.format(scaler.scale_)) #Per feature relative scaling of the data. Equivalent to (max - min) / (X.max(axis=0) - X.min(axis=0))\n",
        "print('scaler.data_range_ = {}'.format(scaler.data_range_)) #Per feature range (data_max_ - data_min_) seen in the data\n",
        "df['Scaled Spending Score'] = scaler.transform(df[['Spending Score']])\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnpIaKzbLE33",
        "colab_type": "text"
      },
      "source": [
        "After features scalling, we will apply k-means clustering again to the scalled features as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_daj1MJiLRde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Scaled_cluster = km.fit_predict(df[['Scaled Annual Income','Scaled Spending Score']])\n",
        "df['Scaled Cluster'] = Scaled_cluster\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL3dGx04LSQ7",
        "colab_type": "text"
      },
      "source": [
        "Let us plot the scalled points (features) using scatter plot but with different colors (based on their new clusters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRxQx7wwMY9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_s0 = df[df['Scaled Cluster'] == 0] \n",
        "df_s1 = df[df['Scaled Cluster'] == 1] \n",
        "df_s2 = df[df['Scaled Cluster'] == 2] \n",
        "df_s3 = df[df['Scaled Cluster'] == 3]\n",
        "plt.scatter(df_s0['Scaled Annual Income'],df_s0['Scaled Spending Score'],color = 'red', label = 'cluster 0')\n",
        "plt.scatter(df_s1['Scaled Annual Income'],df_s1['Scaled Spending Score'],color = 'blue', label = 'cluster 1')\n",
        "plt.scatter(df_s2['Scaled Annual Income'],df_s2['Scaled Spending Score'],color = 'green', label = 'cluster 2')\n",
        "plt.scatter(df_s3['Scaled Annual Income'],df_s3['Scaled Spending Score'],color = 'purple', label = 'cluster 3')\n",
        "plt.xlabel('Scaled Annual Income')\n",
        "plt.ylabel('Scaled Spending Score')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my5Bnp4XAh-y",
        "colab_type": "text"
      },
      "source": [
        "We can also idetify the centroids and plot them on the scatter plot as"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T28JY1c6Atfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "km.cluster_centers_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH0empyvA3Yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_s0 = df[df['Scaled Cluster'] == 0] \n",
        "df_s1 = df[df['Scaled Cluster'] == 1] \n",
        "df_s2 = df[df['Scaled Cluster'] == 2] \n",
        "df_s3 = df[df['Scaled Cluster'] == 3]\n",
        "plt.scatter(df_s0['Scaled Annual Income'],df_s0['Scaled Spending Score'],color = 'red', label = 'cluster 0')\n",
        "plt.scatter(df_s1['Scaled Annual Income'],df_s1['Scaled Spending Score'],color = 'blue', label = 'cluster 1')\n",
        "plt.scatter(df_s2['Scaled Annual Income'],df_s2['Scaled Spending Score'],color = 'green', label = 'cluster 2')\n",
        "plt.scatter(df_s3['Scaled Annual Income'],df_s3['Scaled Spending Score'],color = 'purple', label = 'cluster 3')\n",
        "plt.scatter(km.cluster_centers_[:,0],km.cluster_centers_[:,1],color = 'black', marker = '*', label = 'Centroids', s =80)\n",
        "plt.xlabel('Scaled Annual Income')\n",
        "plt.ylabel('Scaled Spending Score')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbKBUIKQB7Wr",
        "colab_type": "text"
      },
      "source": [
        "Let us try to estimate the sum of the square error (SSE). We will use the inertia_ attribute of the sklearn K-means algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjIYO3EsCJRW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "km.inertia_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fSprZRZC51s",
        "colab_type": "text"
      },
      "source": [
        "Remember, we identified the value of k through observing the scatter plot of the data. However, is this the best k? what if the number of features is large and we can't plot the data. In this case, we will try to get the SQE for different k values, this should be a decreasing curve. Then, we will choose k value just before the SSE flatten. Net we will write a code to identify the best value of k:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOqBdSasEQ_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(df[['Scaled Annual Income']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6w9DngyDyn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SSE=[]\n",
        "for k in range(len(df[['Scaled Annual Income']]),1,-1):\n",
        "    km = KMeans(n_clusters=k)\n",
        "    km.fit_predict(df[['Scaled Annual Income','Scaled Spending Score']])\n",
        "    km.inertia_\n",
        "    SSE.append([k,km.inertia_])\n",
        "SSE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC867TZAFE4p",
        "colab_type": "text"
      },
      "source": [
        "Let us plot this curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sStz3nK2FHzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "SSE=np.array(SSE)\n",
        "plt.plot(SSE[:,0],SSE[:,1],color = 'red')\n",
        "plt.scatter(SSE[:,0],SSE[:,1],color = 'blue')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZXYm0VCGKMy",
        "colab_type": "text"
      },
      "source": [
        "Based on the above curve, k=3 is a better choice for the number of clusters (just before curve flatten).\n",
        "\n",
        "Let us visualize the clustering for k=3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uwVp4R8Go4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_k3 = df[['Scaled Annual Income','Scaled Spending Score']]\n",
        "km = KMeans(n_clusters=3)\n",
        "df_k3['Scaled Cluster'] = km.fit_predict(df_k3[['Scaled Annual Income','Scaled Spending Score']])\n",
        "df_k3.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrcVoGN1H2VC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_s0 = df_k3[df_k3['Scaled Cluster'] == 0] \n",
        "df_s1 = df_k3[df_k3['Scaled Cluster'] == 1] \n",
        "df_s2 = df_k3[df_k3['Scaled Cluster'] == 2] \n",
        "plt.scatter(df_s0['Scaled Annual Income'],df_s0['Scaled Spending Score'],color = 'red', label = 'cluster 0')\n",
        "plt.scatter(df_s1['Scaled Annual Income'],df_s1['Scaled Spending Score'],color = 'blue', label = 'cluster 1')\n",
        "plt.scatter(df_s2['Scaled Annual Income'],df_s2['Scaled Spending Score'],color = 'green', label = 'cluster 2')\n",
        "plt.scatter(km.cluster_centers_[:,0],km.cluster_centers_[:,1],color = 'black', marker = '*', label = 'Centroids', s =80)\n",
        "plt.xlabel('Scaled Annual Income')\n",
        "plt.ylabel('Scaled Spending Score')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0GIno0mItLL",
        "colab_type": "text"
      },
      "source": [
        "**What do you think? Is this a better way of clustering the point?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-tGDrurR4jo",
        "colab_type": "text"
      },
      "source": [
        "Another approach to determine the best k value is by using the silhouette metric.\n",
        "\n",
        "Silhouette score tells how far away the datapoints in one cluster are, from the datapoints in another cluster. The range of silhouette score is from -1 to 1. Score should be closer to 1 than -1.$^{[1]}$\n",
        "\n",
        "[1] https://towardsdatascience.com/k-means-clustering-from-a-to-z-f6242a314e9a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Mn7l7ZBSTgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "for k in range(2,len(df[['Scaled Annual Income']])):\n",
        "    km = KMeans(n_clusters=k)\n",
        "    X = df[['Scaled Annual Income','Scaled Spending Score']]\n",
        "    cluster_labels = km.fit_predict(X)\n",
        "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "    print(\"For n_clusters =\", k,\n",
        "          \"The average silhouette_score is :\", silhouette_avg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc0Hph4_XKNx",
        "colab_type": "text"
      },
      "source": [
        "The Silhouette score indicates that thre best number of clusters is 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIgCwet8SjNR",
        "colab_type": "text"
      },
      "source": [
        "# Case #2: Recognition of Handwritten Digits\n",
        "\n",
        "In this section, we will fine tune the parameters of **RandomForest** (RF) using the **K-Fold Cross Validation** to recognize handwritten digits using . We will be using a standard dataset available through the sklearn library called \"load_digits\".$^{[1][2]}$\n",
        "\n",
        "[1] https://scikit-learn.org/stable/tutorial/basic/tutorial.html#introduction\n",
        "\n",
        "[2] https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html\n",
        "\n",
        "[3] https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-clustering-1.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQdZcUD-BBMi",
        "colab_type": "text"
      },
      "source": [
        "**implementation** (you may run the first few cells quickly if you have done this probem in the the previous tutorials)\n",
        "\n",
        "In the beginning, we will load the dataset as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thCgqt3KSpwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGRXkAwRMDWg",
        "colab_type": "text"
      },
      "source": [
        "A dataset is a dictionary-like object that holds all the data and some metadata about the data. Let us explore the content of the digits dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8qlgSoRTAhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir(digits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEbzkkNqMLZf",
        "colab_type": "text"
      },
      "source": [
        "The digits.data contains the features that will be used to classify the digits samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lw41j9WUlr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(digits.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_ZbG54iNTgV",
        "colab_type": "text"
      },
      "source": [
        "The digits.images contains the images of the digits samples. They can be viewed using the following code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsM4ZMMWXGBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.gray()\n",
        "plt.matshow(digits.images[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK1cRXeTNmwf",
        "colab_type": "text"
      },
      "source": [
        "The ground truth of the datset is stored in the digits.taget"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX5YG-S-UxiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(digits.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy6FObMY7yo2",
        "colab_type": "text"
      },
      "source": [
        "Let us use Principle Component Analysis to view the digits dataset. We will lot a projection on the 2 first principal axis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJA-IsUh7zxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "proj = pca.fit_transform(digits.data)\n",
        "plt.scatter(proj[:, 0], proj[:, 1], c=digits.target, cmap=\"Paired\")\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc0cKNwJN45-",
        "colab_type": "text"
      },
      "source": [
        "After exploring the content of the digits dataset, we will cluster the dataset into 10 clusters. First, we decide the input feature vector (x) and the ground truth (y) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jSk9q-BU-1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = digits.data\n",
        "y = digits.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jISXYms6C3-W",
        "colab_type": "text"
      },
      "source": [
        "To fit and predict (cluster) the dataset using KMeans we use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fbrotPpw6Fr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "km = KMeans( n_clusters = 10 )\n",
        "km.fit_predict( x )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_E4YqtDDUzD",
        "colab_type": "text"
      },
      "source": [
        "The KMeans cluster centers are also computed while fit and predict step. However, it will be difficult to draw them because of each point has 10 features (need to view in 10 Dimensions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbGWmWE7L-0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "km_cluster_centers_ = km.cluster_centers_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeyKDKEeEevt",
        "colab_type": "text"
      },
      "source": [
        "To measure the accuracy (purity) of the KMeans clustering, we need to compare the KMeans clustering labels and the ground truth. Before doing that, we need to correlate the actual labels with the KMeans cluster numbers. To do this we will \\\\\n",
        "1- compute the centroid of each of the labeled datasets (ground truth centroids) \\\\\n",
        "2- compute Sum of Squared Difference (SSD) between KMeans centroids and ground truth centroids, \\\\\n",
        "3- couple KMeans labels with ground truth based on minimum SSD."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCaGBNv4F-F3",
        "colab_type": "text"
      },
      "source": [
        "In here, we compute the ground truth centroids (digits_cluster_centers_)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymKlaphZ3OfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digits_cluster_centers_=[]\n",
        "km_ = KMeans( n_clusters = 1)\n",
        "for k in range(10):\n",
        "  Idx = np.where(digits.target == k)\n",
        "  x_ = digits.data[Idx]\n",
        "  km_.fit_predict(x_)\n",
        "  digits_cluster_centers_.append(km_.cluster_centers_[0,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc_jcAAGGIe6",
        "colab_type": "text"
      },
      "source": [
        "2- Compute SSD between KMeans centroids and ground truth centroids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfHa75zjB2XY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SSD=np.zeros([10,10])\n",
        "for i in range(10):\n",
        "  for j in range(10):\n",
        "    SSD[i,j] = np.sum((digits_cluster_centers_[i][:]-km.cluster_centers_[j][:])**2)\n",
        "  SSD = np.round(SSD)\n",
        "print(SSD)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hARLx-6q8ePK",
        "colab_type": "text"
      },
      "source": [
        "3- Couple KMeans labels with ground truth based on minimum SSD\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTEeU2WX9U2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Idx_=[]\n",
        "for i in range(10):\n",
        "  Idx = np.where(SSD == np.min(SSD))\n",
        "  SSD[int(Idx[0][0]),int(Idx[1][0])] = math.inf\n",
        "  SSD[int(Idx[0][0]),:] = math.inf\n",
        "  SSD[:,int(Idx[1][0])] = math.inf\n",
        "  Idx_.append([int(Idx[0][0]),int(Idx[1][0])])\n",
        "print(Idx_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaiyY71lI_vC",
        "colab_type": "text"
      },
      "source": [
        "To visualize the KMeans labels and ground truth labels, use the following code. The text on the left of each image is the ground truth label and the text on the right is the KMeans label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qT04l-eIOf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "fig = plt.figure(figsize=(12, 24))  # figure size in inches\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "import math\n",
        "for k in range(10):\n",
        "  x_ = digits.data[int(Idx_[k][0])]\n",
        "  ax = fig.add_subplot(16, 8, k + 1, xticks=[], yticks=[])\n",
        "  ax.imshow(digits.images[int(Idx_[k][0])], cmap=plt.cm.binary, interpolation='nearest')\n",
        "  # label the image with the target value\n",
        "  ax.text(0, 7, str(int(Idx_[k][0])))\n",
        "  ax.text(6.5, 7, str(int(Idx_[k][1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCrSkAx0IWag",
        "colab_type": "text"
      },
      "source": [
        "To view all datapoint with KMeans label \"7\" which is equivalent to ground truth label \"4\", use the following code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z-TIhd9IR-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "Idx_plt = np.array(np.where ( km.labels_ == 7 )) ## 7 is the KMeans cluster label\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(12, 24))  # figure size in inches\n",
        "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
        "for k in range(24):\n",
        "  x_ = digits.data[int(Idx_plt[0][k])]\n",
        "  ax = fig.add_subplot(16, 8, k + 1, xticks=[], yticks=[])\n",
        "  ax.imshow(digits.images[int(Idx_plt[0][k])], cmap=plt.cm.binary, interpolation='nearest')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aizOkQMzUEEV",
        "colab_type": "text"
      },
      "source": [
        "To measure the purity (accuracy) of the KMeans, run the following"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QMSy4U5MvCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Idx_ = np.array(Idx_)\n",
        "Idx_s = Idx_[Idx_[:,0].argsort()]\n",
        "error_pure = 0\n",
        "for i in range(len(digits.target)):\n",
        "  if not ( km.labels_[i] == Idx_s[digits.target[i]][1]):\n",
        "    error_pure+=1\n",
        "km_accuracy = 100 * (1 - error_pure / len(digits.target))\n",
        "print(km_accuracy)\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clLdKNnsVLSK",
        "colab_type": "text"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "**Exercise #1**\n",
        "\n",
        "**Exercise #2**"
      ]
    }
  ]
}