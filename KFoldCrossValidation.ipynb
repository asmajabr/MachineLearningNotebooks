{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KFoldCrossValidation.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkjubran/MachineLearningNotebooks/blob/master/KFoldCrossValidation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzmEcNHzuBI3",
        "colab_type": "text"
      },
      "source": [
        "# Clone the Source GitHub Reporsitory \n",
        "We need to clone some source files to be used throughtout this tutorial from a GitHub reprository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmP4GrRNudXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./MachineLearning\n",
        "!git clone https://github.com/mkjubran/MachineLearning.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge4LeJuiweBs",
        "colab_type": "text"
      },
      "source": [
        "(Optional) You may also disable future warning through running the following code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzzwDVhjwbt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIlzJbCpmo0R",
        "colab_type": "text"
      },
      "source": [
        "# K-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrMDfwQQzBEn",
        "colab_type": "text"
      },
      "source": [
        "**Readings and Resources**\n",
        "\n",
        "[1] https://medium.com/datadriveninvestor/k-fold-cross-validation-6b8518070833\n",
        "\n",
        "[2] https://scikit-learn.org/stable/modules/cross_validation.html\n",
        "\n",
        "[3] https://machinelearningmastery.com/k-fold-cross-validation/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOQvdG9QW1Yv",
        "colab_type": "text"
      },
      "source": [
        "# Case #1: Studying Hours and Passing Exams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7ietEiOzhNl",
        "colab_type": "text"
      },
      "source": [
        "In this section, we will compare the performance of different ML techniques applied to the \"Studying Hours and Passing Exams\" case using the **K-Fold Cross Validation** (KCV) Method. We assume you have some experience or have practiced each of these ML techniques using our tutorials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RSwASngm9_9",
        "colab_type": "text"
      },
      "source": [
        "**Implementation** *(you may run the first few cells quickly if you have done this probem in the the previous tutorials)*\n",
        "\n",
        "Read the input data (number of study hours and exam pass or fail) from the csv file (HoursPassExam.csv) file. Use the pandas library (https://pandas.pydata.org/) to read the data from the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQX2iq_fnJOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"./MachineLearning/6_KFold_Cross_Validation/HoursPassExam.csv\")\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39M2I3LU70dB",
        "colab_type": "text"
      },
      "source": [
        "As can be seen, the output (pass) is binary; 0 for failing the exam and 1 for passing the exam. Next, we will divide the dataset into K training and testing datasets using the **K-Fold Cross Validation** (KVC) Method. However, before doing that let us show a simple example of using the **KVC** method.\n",
        "\n",
        "Let us assume a dataset of integers from 0 to 10. We will use the **KVC** to split this dataset into 4 training and testing datasets as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOSm3Wbnjo4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = KFold( n_splits = 4 )\n",
        "for train_index, test_index in kf.split([0,1,2,3,4,5,6,7,8,9,10]):\n",
        "  print(train_index,test_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rJcVSVxkMPU",
        "colab_type": "text"
      },
      "source": [
        "As can be observed that the datset is split into 4 none overlapping test datasets. The size of the dataset split (test and training) depends on the requested number of dataset splits (n_splits).\n",
        "\n",
        "Let split the same dataset into 3 splits (n_splits = 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDtE8Sr4lG-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kf = KFold( n_splits = 3 )\n",
        "for train_index, test_index in kf.split([0,1,2,3,4,5,6,7,8,9,10]):\n",
        "  print(train_index,test_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juQsSR3VlLUS",
        "colab_type": "text"
      },
      "source": [
        "Let us now get the **KVC** of the students pass/fail dataset with n_splits = 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_DU2wn6lk9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kf = KFold( n_splits = 4 )\n",
        "for train_index, test_index in kf.split(range(df.shape[0])):\n",
        "  print(train_index,test_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSMBwo68nBO0",
        "colab_type": "text"
      },
      "source": [
        "To determine the traing and testing datasets we will define x and y, and then define the x_train, x_test and y_train and y_test based on the train_index and test_index as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uIoyL855AoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df[['hours']] # two dimension array\n",
        "y = df['pass']\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold( n_splits = 4 )\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model_lr = LogisticRegression()\n",
        "ACC_train_lr = []\n",
        "ACC_test_lr = []\n",
        "\n",
        "import numpy as np\n",
        "for train_index,test_index in kf.split(range(df.shape[0])):\n",
        "   y_train = [y[i] for i in train_index]\n",
        "   y_test = [y[i] for i in test_index]\n",
        "   x_train = [np.array(x)[i,:] for i in train_index]\n",
        "   x_test = [np.array(x)[i,:] for i in test_index]\n",
        "   print('Size of dataset: x_traing = {}, x_test = {}, y_train = {}, y_test {}'.format(len(x_train),len(x_test),len(y_train),len(y_test)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3B2xf9y60Xm",
        "colab_type": "text"
      },
      "source": [
        "Let us know apply the logistic regression to the **KVC** train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aocFZ_aGp56k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df[['hours']] # two dimension array\n",
        "y = df['pass']\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold( n_splits = 4 )\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model_lr = LogisticRegression()\n",
        "ACC_train_lr = []\n",
        "ACC_test_lr = []\n",
        "\n",
        "import numpy as np\n",
        "for train_index,test_index in kf.split(range(df.shape[0])):\n",
        "   y_train = [y[i] for i in train_index]\n",
        "   y_test = [y[i] for i in test_index]\n",
        "   x_train = [np.array(x)[i,:] for i in train_index]\n",
        "   x_test = [np.array(x)[i,:] for i in test_index]\n",
        "   model_lr.fit(x_train, y_train)\n",
        "   ACC_train_lr.append(model_lr.score(x_train, y_train))\n",
        "   ACC_test_lr.append(model_lr.score(x_test, y_test))\n",
        "\n",
        "ACC_train_lr = np.mean(ACC_train_lr)\n",
        "ACC_test_lr = np.mean(ACC_test_lr)\n",
        "\n",
        "print(ACC_train_lr)\n",
        "print(ACC_test_lr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN5lsycN-QLl",
        "colab_type": "text"
      },
      "source": [
        "To compare different ML technqiues in an efficient way, we will write the model fitting and score computation as a function as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie6MQtv4-dsp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ACC_ML(model, x_train,x_test,y_train,y_test, ACC_train, ACC_test):\n",
        "   model.fit(x_train, y_train)\n",
        "   ACC_train.append(model.score(x_train, y_train))\n",
        "   ACC_test.append(model.score(x_test, y_test))\n",
        "   return ACC_train,ACC_test\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHBzokno-6La",
        "colab_type": "text"
      },
      "source": [
        "Now we repeat the model evaluation using the ACC_ML() function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2BmOb-E_GxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df[['hours']] # two dimension array\n",
        "y = df['pass']\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold( n_splits = 4 )\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "ACC_train_lr = []\n",
        "ACC_test_lr = []\n",
        "\n",
        "import numpy as np\n",
        "for train_index,test_index in kf.split(range(df.shape[0])):\n",
        "   y_train = [y[i] for i in train_index]\n",
        "   y_test = [y[i] for i in test_index]\n",
        "   x_train = [np.array(x)[i,:] for i in train_index]\n",
        "   x_test = [np.array(x)[i,:] for i in test_index]\n",
        "\n",
        "   ## logistic regression\n",
        "   ACC_train_lr, ACC_test_lr = ACC_ML(LogisticRegression(), x_train,x_test,y_train,y_test, ACC_train_lr, ACC_test_lr)\n",
        "\n",
        "ACC_train_lr = np.mean(ACC_train_lr)\n",
        "ACC_test_lr = np.mean(ACC_test_lr)\n",
        "\n",
        "print(ACC_train_lr)\n",
        "print(ACC_test_lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sROcI4BP_-E0",
        "colab_type": "text"
      },
      "source": [
        "Let us try to compare Logistic Regression (**LR**), Decision Tree (**DT**), Support Vector Machine (**SVM**), Random Forest (**RF**), and **Naive Bayes** ML techqniues"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-KEl9nh__IT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df[['hours']] # two dimension array\n",
        "y = df['pass']\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold( n_splits = 4 )\n",
        "\n",
        "##LR\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "ACC_train_lr = []; ACC_test_lr = []\n",
        "\n",
        "##DT\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "ACC_train_dt = []; ACC_test_dt = []\n",
        "\n",
        "##SVM\n",
        "from sklearn.svm import SVC\n",
        "ACC_train_svm = []; ACC_test_svm = []\n",
        "\n",
        "##RF\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "ACC_train_rf = []; ACC_test_rf = []\n",
        "\n",
        "##NB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "ACC_train_nb = []; ACC_test_nb = []\n",
        "\n",
        "import numpy as np\n",
        "for train_index,test_index in kf.split(range(df.shape[0])):\n",
        "   y_train = [y[i] for i in train_index]\n",
        "   y_test = [y[i] for i in test_index]\n",
        "   x_train = [np.array(x)[i,:] for i in train_index]\n",
        "   x_test = [np.array(x)[i,:] for i in test_index]\n",
        "\n",
        "   ## LR\n",
        "   ACC_train_lr, ACC_test_lr = ACC_ML(LogisticRegression(), x_train,x_test,y_train,y_test, ACC_train_lr, ACC_test_lr)\n",
        "\n",
        "   ##DT\n",
        "   ACC_train_dt, ACC_test_dt = ACC_ML(DecisionTreeClassifier(), x_train,x_test,y_train,y_test, ACC_train_dt, ACC_test_dt)\n",
        "\n",
        "\n",
        "   ##SVM\n",
        "   ACC_train_svm, ACC_test_svm = ACC_ML(SVC(), x_train,x_test,y_train,y_test, ACC_train_svm, ACC_test_svm)\n",
        " \n",
        "   ##RF\n",
        "   ACC_train_rf, ACC_test_rf = ACC_ML(RandomForestClassifier(), x_train,x_test,y_train,y_test, ACC_train_rf, ACC_test_rf)\n",
        "\n",
        "   ##NB\n",
        "   ACC_train_nb, ACC_test_nb = ACC_ML(GaussianNB(), x_train,x_test,y_train,y_test, ACC_train_nb, ACC_test_nb)\n",
        "  \n",
        "## compute the mean of accuracy of the K-Fold datasets\n",
        "ACC_train_lr_mean = np.mean(ACC_train_lr); ACC_test_lr_mean = np.mean(ACC_test_lr);\n",
        "ACC_train_dt_mean = np.mean(ACC_train_dt); ACC_test_dt_mean = np.mean(ACC_test_dt);\n",
        "ACC_train_svm_mean = np.mean(ACC_train_svm); ACC_test_svm_mean = np.mean(ACC_test_svm);\n",
        "ACC_train_rf_mean = np.mean(ACC_train_rf); ACC_test_rf_mean = np.mean(ACC_test_rf);\n",
        "ACC_train_nb_mean = np.mean(ACC_train_nb); ACC_test_nb_mean = np.mean(ACC_test_nb);\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'Logistic (%)' , 'DT (%)' , 'SVM (%)' , 'RF (%)', 'NB (%)'])\n",
        "t.add_row(['Training', ACC_train_lr_mean*100, ACC_train_dt_mean*100, ACC_train_svm_mean*100, ACC_train_rf_mean*100, ACC_train_nb_mean*100])\n",
        "t.add_row(['Testing', ACC_test_lr_mean*100, ACC_test_dt_mean*100, ACC_test_svm_mean*100, ACC_test_rf_mean*100, ACC_test_nb_mean*100])\n",
        "print(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81vG6_ZYs487",
        "colab_type": "text"
      },
      "source": [
        "Thanks to sklearn library, we don't have to do all of this code to get the **KCV** score. We can use the "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jamgnusatJfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df[['hours']] # two dimension array\n",
        "y = df['pass']\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "##LR\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "ACC_test_lr = cross_val_score(LogisticRegression(),x,y)\n",
        "\n",
        "##DT\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "ACC_test_dt = cross_val_score(DecisionTreeClassifier(),x,y)\n",
        "\n",
        "##SVM\n",
        "from sklearn.svm import SVC\n",
        "ACC_test_svm = cross_val_score(SVC(),x,y)\n",
        "\n",
        "##RF\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "ACC_test_rf = cross_val_score(RandomForestClassifier(),x,y)\n",
        "\n",
        "##NB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "ACC_test_nb = cross_val_score(GaussianNB(),x,y)\n",
        "\n",
        "ACC_test_lr_mean = np.mean(ACC_test_lr);\n",
        "ACC_test_dt_mean = np.mean(ACC_test_dt);\n",
        "ACC_test_svm_mean = np.mean(ACC_test_svm);\n",
        "ACC_test_rf_mean = np.mean(ACC_test_rf);\n",
        "ACC_test_nb_mean = np.mean(ACC_test_nb);\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'Logistic (%)' , 'DT (%)' , 'SVM (%)' , 'RF (%)', 'NB (%)'])\n",
        "t.add_row(['Testing', ACC_test_lr_mean*100, ACC_test_dt_mean*100, ACC_test_svm_mean*100, ACC_test_rf_mean*100, ACC_test_nb_mean*100])\n",
        "print(t)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbzogbvTw7M4",
        "colab_type": "text"
      },
      "source": [
        "To get the training accuracy, training time, and score time you may use the following code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6_m5Ih-xJDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df[['hours']] # two dimension array\n",
        "y = df['pass']\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "##LR\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "Score_lr = cross_validate(LogisticRegression(),x,y,return_train_score=True)\n",
        "ACC_test_lr = np.mean(Score_lr['test_score'])\n",
        "ACC_train_lr = np.mean(Score_lr['train_score'])\n",
        "fit_time_lr = np.mean(Score_lr['fit_time'])\n",
        "score_time_lr = np.mean(Score_lr['score_time'])\n",
        "\n",
        "##DT\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "Score_dt = cross_validate(DecisionTreeClassifier(),x,y,return_train_score=True)\n",
        "ACC_test_dt = np.mean(Score_dt['test_score'])\n",
        "ACC_train_dt = np.mean(Score_dt['train_score'])\n",
        "fit_time_dt = np.mean(Score_dt['fit_time'])\n",
        "score_time_dt = np.mean(Score_dt['score_time'])\n",
        "\n",
        "##SVM\n",
        "from sklearn.svm import SVC\n",
        "Score_svm = cross_validate(SVC(),x,y,return_train_score=True)\n",
        "ACC_test_svm = np.mean(Score_svm['test_score'])\n",
        "ACC_train_svm = np.mean(Score_svm['train_score'])\n",
        "fit_time_svm = np.mean(Score_svm['fit_time'])\n",
        "score_time_svm = np.mean(Score_svm['score_time'])\n",
        "\n",
        "##RF\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "Score_rf = cross_validate(RandomForestClassifier(),x,y,return_train_score=True)\n",
        "ACC_test_rf = np.mean(Score_rf['test_score'])\n",
        "ACC_train_rf = np.mean(Score_rf['train_score'])\n",
        "fit_time_rf = np.mean(Score_rf['fit_time'])\n",
        "score_time_rf = np.mean(Score_rf['score_time'])\n",
        "\n",
        "##NB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "Score_nb = cross_validate(GaussianNB(),x,y,return_train_score=True)\n",
        "ACC_test_nb = np.mean(Score_nb['test_score'])\n",
        "ACC_train_nb = np.mean(Score_nb['train_score'])\n",
        "fit_time_nb = np.mean(Score_nb['fit_time'])\n",
        "score_time_nb = np.mean(Score_nb['score_time'])\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'Logistic' , 'DT' , 'SVM' , 'RF', 'NB'])\n",
        "t.add_row(['Training (%)', ACC_train_lr*100, ACC_train_dt*100, ACC_train_svm*100, ACC_train_rf*100, ACC_train_nb*100])\n",
        "t.add_row(['Testing (%)', ACC_test_lr*100, ACC_test_dt*100, ACC_test_svm*100, ACC_test_rf*100,  ACC_test_nb*100])\n",
        "t.add_row(['fit_time', fit_time_lr, fit_time_dt, fit_time_svm, fit_time_rf, fit_time_nb])\n",
        "t.add_row(['score_time', score_time_lr, score_time_dt, score_time_svm, score_time_rf, score_time_nb])\n",
        "print(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5dxmJdmDoPs",
        "colab_type": "text"
      },
      "source": [
        "The k (n_splits) value must be chosen carefully for your datasets. A poorly chosen value for k may result in a mis-representative idea of the skill of the model, such as a score with a high variance (that may change a lot based on the data used to fit the model), or a high bias, (such as an overestimate of the skill of the model). $^{[1]}$\n",
        "\n",
        "Three common tactics for choosing a value for k are as follows $^{[1]}$:\n",
        "\n",
        "1- Representative: The value for k is chosen such that each train/test group of data samples is large enough to be statistically representative of the broader dataset.\n",
        "\n",
        "2- k=10: The value for k is fixed to 10, a value that has been found through experimentation to generally result in a model skill estimate with low bias a modest variance.\n",
        "\n",
        "3- k=n: The value for k is fixed to n, where n is the size of the dataset to give each test sample an opportunity to be used in the hold out dataset. This approach is called leave-one-out cross-validation.\n",
        "\n",
        "[1] https://machinelearningmastery.com/k-fold-cross-validation/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB7m0dsJ34AC",
        "colab_type": "text"
      },
      "source": [
        "Let us try **KCV** with k=10 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEYcdhUS33p3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df[['hours']] # two dimension array\n",
        "y = df['pass']\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "cv_value = 10\n",
        "##LR\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "ACC_test_lr = cross_val_score(LogisticRegression(),x,y,cv = cv_value)\n",
        "\n",
        "##DT\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "ACC_test_dt = cross_val_score(DecisionTreeClassifier(),x,y,cv = cv_value)\n",
        "\n",
        "##SVM\n",
        "from sklearn.svm import SVC\n",
        "ACC_test_svm = cross_val_score(SVC(),x,y,cv = cv_value)\n",
        "\n",
        "##RF\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "ACC_test_rf = cross_val_score(RandomForestClassifier(),x,y,cv = cv_value)\n",
        "\n",
        "##NB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "ACC_test_nb = cross_val_score(GaussianNB(),x,y,cv = cv_value)\n",
        "\n",
        "ACC_test_lr_mean = np.mean(ACC_test_lr);\n",
        "ACC_test_dt_mean = np.mean(ACC_test_dt);\n",
        "ACC_test_svm_mean = np.mean(ACC_test_svm);\n",
        "ACC_test_rf_mean = np.mean(ACC_test_rf);\n",
        "ACC_test_nb_mean = np.mean(ACC_test_nb);\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'Logistic (%)' , 'DT (%)' , 'SVM (%)' , 'RF (%)', 'NB (%)'])\n",
        "t.add_row(['Testing', ACC_test_lr_mean*100, ACC_test_dt_mean*100, ACC_test_svm_mean*100, ACC_test_rf_mean*100, ACC_test_nb_mean*100])\n",
        "print(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSLLJYwU25ao",
        "colab_type": "text"
      },
      "source": [
        "Let us try the **leave-one-out cross-validation** approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROIQsYjD274K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## compute maximum posssible cv values\n",
        "x = df[['hours']] # two dimension array\n",
        "y = df['pass']\n",
        "y_0 =  df[df['pass'] == 0]\n",
        "y_1 =  df[df['pass'] == 1]\n",
        "cv_value = int(min(y_0.shape[0], y_1.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSzCRCom3NwN",
        "colab_type": "text"
      },
      "source": [
        "Use cross_val_score with this cv_value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9ebeLvz0iRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df[['hours']] # two dimension array\n",
        "y = df['pass']\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "##LR\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "ACC_test_lr = cross_val_score(LogisticRegression(),x,y,cv = cv_value)\n",
        "\n",
        "##DT\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "ACC_test_dt = cross_val_score(DecisionTreeClassifier(),x,y,cv = cv_value)\n",
        "\n",
        "##SVM\n",
        "from sklearn.svm import SVC\n",
        "ACC_test_svm = cross_val_score(SVC(),x,y,cv = cv_value)\n",
        "\n",
        "##RF\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "ACC_test_rf = cross_val_score(RandomForestClassifier(),x,y,cv = cv_value)\n",
        "\n",
        "\n",
        "##NB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "ACC_test_nb = cross_val_score(GaussianNB(),x,y,cv = cv_value)\n",
        "\n",
        "ACC_test_lr_mean = np.mean(ACC_test_lr);\n",
        "ACC_test_dt_mean = np.mean(ACC_test_dt);\n",
        "ACC_test_svm_mean = np.mean(ACC_test_svm);\n",
        "ACC_test_rf_mean = np.mean(ACC_test_rf);\n",
        "ACC_test_nb_mean = np.mean(ACC_test_nb);\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'Logistic (%)' , 'DT (%)' , 'SVM (%)' , 'RF (%)', 'NB (%)'])\n",
        "t.add_row(['Testing', ACC_test_lr_mean*100, ACC_test_dt_mean*100, ACC_test_svm_mean*100, ACC_test_rf_mean*100, ACC_test_nb_mean*100])\n",
        "print(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjDEZfJP4RqQ",
        "colab_type": "text"
      },
      "source": [
        "Comparing the two options of k values above emphasize the importance of selecting the right value of k. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "663TS4Ok4_-z",
        "colab_type": "text"
      },
      "source": [
        "The **KCV** can also be used during parameter tuning of any ML technique. Let us use the **KCV** to tune the number of trees in the Random Forest Classifier (the default value is \"n_estimators = 100\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNZDfI880S2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df[['hours']] # two dimension array\n",
        "y = df['pass']\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['n_estimators','Accuracy of RF'])\n",
        "\n",
        "##RF (cv = 10)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "for n_trees in range(10,200,10):\n",
        "  Score_rf = cross_validate(RandomForestClassifier(n_estimators = n_trees),x,y,return_train_score=True, cv = 10)\n",
        "  ACC_test_rf = np.mean(Score_rf['test_score'])\n",
        "  t.add_row([n_trees, ACC_test_rf*100])\n",
        "\n",
        "print(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH1COvVuXwR5",
        "colab_type": "text"
      },
      "source": [
        "# Case #2: HR Analysis\n",
        "\n",
        "In this section, we will compare the performance of different ML techniques applied to the \"HR Analysis\" case using the **K-Fold Cross Validation** (KCV) method. We assume you have some experience or have practiced each of these ML techniques using our tutorials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eR70Y6nbQYs",
        "colab_type": "text"
      },
      "source": [
        "**Implementation** *(you may run the first few cells quickly if you have done this probem in the the previous tutorials)*\n",
        "\n",
        "Read the input data from the csv file (HR_comma_sep.csv) file. Dataset is downloaded from Kaggle. Link: https://www.kaggle.com/giripujar/hr-analytics. Use the pandas library (https://pandas.pydata.org/) to read the data from the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZrjhWA3YRcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "HR = pd.read_csv('./MachineLearning/5_random_forest/HR_comma_sep.csv')\n",
        "HR.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RpPISukQ7AW",
        "colab_type": "text"
      },
      "source": [
        "To get some information about the read dataset use the pandas info method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trVn1MFTQ7gq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HR.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEVwPozTbhm6",
        "colab_type": "text"
      },
      "source": [
        "Before applying classification to the data, we will explore and analyze the data to determine the features that influence the decision of the employee to remain or leave the company."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5PfSFCycBBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "left = HR[HR.left==1] ## employees who left the company \n",
        "No_left= left.shape[0]\n",
        "remain = HR[HR.left==0] ## employees who remain at the company \n",
        "No_remain = remain.shape[0]\n",
        "Per_left = No_left / (No_left + No_remain)\n",
        "\n",
        "print('No_left = {}, No_remain = {} , Percentage of left = {} %'.format(No_left,No_remain,Per_left*100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R61IR-gJdNQQ",
        "colab_type": "text"
      },
      "source": [
        "About $23\\%$ employees left the company. Now, let us check which features are mostly affecting the decision of employees to leave or remain in the company. To do this, we will measure the average of each numeric feature for employees to remain or leave the company.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmI7sVO4d6vG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HR.groupby('left').mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY7uKIrGeOIQ",
        "colab_type": "text"
      },
      "source": [
        "We may conclude the following from the table above: \\\\\n",
        "1- Employees who remain in the company has higher satisfaction_level and thus it is a good indicator for our regression/classifier (good feature) \\\\\n",
        "2- The last_evaluation, number of projects, and time_spend_company scores are almost independent of the employees remain or leave the company \\\\\n",
        "3- The average_montly_hours for employees who left the company are higher than those who remained which could be an indicator (good feature) \\\\\n",
        "4- The promotion_last_5years feature of employees remaining in the company is much higher than those left the company (good feature) \\\\\n",
        "5- Work_accident is also an indicator so it is a good feature.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MlXIibs9Z8R",
        "colab_type": "text"
      },
      "source": [
        "Let us also check the quality of the categories' features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0Rf5SjP6Ix8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.crosstab(HR.salary,HR.left)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWOZE5NBy5ru",
        "colab_type": "text"
      },
      "source": [
        "The salary table shows that emloyees with high salaries are more likely to stay in the company. So it is a good feature. To visualize this we make a bar plot as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xIPIbJ5965b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.crosstab(HR.salary,HR.left).plot(kind='bar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q0QfTZjzPs2",
        "colab_type": "text"
      },
      "source": [
        "We need also to investigate the department feature as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCHfkCyz-B-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.crosstab(HR.Department,HR.left).plot(kind='bar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT1gQWr30YT0",
        "colab_type": "text"
      },
      "source": [
        "The department type has a minor effect on the decision of employees to stay or leave the company. It doesn't look a major factor and thus we will ignore this feature. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3okSyzEL8HzB",
        "colab_type": "text"
      },
      "source": [
        "Based on the above analysis, we will create the following table which includes only the good (important, major) features affecting employees decisions to stay or leave the company"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2I6qW3L5XS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HR_GF = HR[['left','satisfaction_level','average_montly_hours','Work_accident','promotion_last_5years', 'salary']]\n",
        "HR_GF.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fR496PVVYaA",
        "colab_type": "text"
      },
      "source": [
        "Let us plot this data for better visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glqeH5PrVYn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "HR_GF_0 = HR_GF[HR_GF['left'] == 0]\n",
        "HR_GF_1 = HR_GF[HR_GF['left'] == 1]\n",
        "\n",
        "fig, axes = plt.subplots(2, 4,figsize = (20,10))\n",
        "axes[0,0].scatter(HR_GF_0['satisfaction_level'], HR_GF_0['average_montly_hours'], color = 'blue', marker ='+')\n",
        "axes[0,0].set_xlabel('satisfaction_level')\n",
        "axes[0,0].set_ylabel('average_montly_hours')\n",
        "\n",
        "axes[0,1].scatter(HR_GF_0['satisfaction_level'], HR_GF_0['Work_accident'], color = 'blue', marker ='+')\n",
        "axes[0,1].set_xlabel('satisfaction_level')\n",
        "axes[0,1].set_ylabel('Work_accident')\n",
        "\n",
        "axes[0,2].scatter(HR_GF_0['satisfaction_level'], HR_GF_0['promotion_last_5years'], color = 'blue', marker ='+')\n",
        "axes[0,2].set_xlabel('satisfaction_level')\n",
        "axes[0,2].set_ylabel('promotion_last_5years')\n",
        "\n",
        "axes[0,3].scatter(HR_GF_0['satisfaction_level'], HR_GF_0['salary'], color = 'blue', marker ='+')\n",
        "axes[0,3].set_xlabel('satisfaction_level')\n",
        "axes[0,3].set_ylabel('salary')\n",
        "\n",
        "axes[1,0].scatter(HR_GF_1['satisfaction_level'], HR_GF_1['average_montly_hours'], color = 'orange', marker ='s')\n",
        "axes[1,0].set_xlabel('satisfaction_level')\n",
        "axes[1,0].set_ylabel('average_montly_hours')\n",
        "\n",
        "axes[1,1].scatter(HR_GF_1['satisfaction_level'], HR_GF_1['Work_accident'], color = 'orange', marker ='s')\n",
        "axes[1,1].set_xlabel('satisfaction_level')\n",
        "axes[1,1].set_ylabel('Work_accident')\n",
        "\n",
        "axes[1,2].scatter(HR_GF_1['satisfaction_level'], HR_GF_1['promotion_last_5years'], color = 'orange', marker ='s')\n",
        "axes[1,2].set_xlabel('satisfaction_level')\n",
        "axes[1,2].set_ylabel('promotion_last_5years')\n",
        "\n",
        "axes[1,3].scatter(HR_GF_1['satisfaction_level'], HR_GF_1['salary'], color = 'orange', marker ='s')\n",
        "axes[1,3].set_xlabel('satisfaction_level')\n",
        "axes[1,3].set_ylabel('salary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ho-hLuj1bTz",
        "colab_type": "text"
      },
      "source": [
        "By comparing the top and bottom figures, the dataset is separable with respect to the left feature.\n",
        "\n",
        "**For the ML algorithms**, we need to convert categories features into numbers. We will use label encoder from sklearn library to encode the category feature (salary) as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4vXoCKhHwx9",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le_salary = LabelEncoder()\n",
        "HR_GF_LE = pd.DataFrame.copy(HR_GF)\n",
        "HR_GF_LE['salary'] = le_salary.fit_transform(HR_GF_LE['salary'])\n",
        "HR_GF_LE.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYVPPi0N4AR_",
        "colab_type": "text"
      },
      "source": [
        "Let us define input (x) and output (y) of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ercG4Iwd4A-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = HR_GF_LE.drop('left',axis=1)\n",
        "y = HR_GF_LE.left"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy19UnJg6lXy",
        "colab_type": "text"
      },
      "source": [
        "Use one-hot-encoding for salary to be used by logitic regression algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt6ml3p76l4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## add column for logitic regression (training)\n",
        "dm = pd.get_dummies(x.salary)\n",
        "x_lr = pd.concat([x,dm],axis=1)\n",
        "x_lr = x_lr.drop(['salary',2],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRyJhrij4oAB",
        "colab_type": "text"
      },
      "source": [
        "Now, we are ready to apply **KCV** to compare the performance of the different ML techniques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wVAxuJm4pMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "##LR\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "Score_lr = cross_validate(LogisticRegression(),x_lr,y,return_train_score=True) ##x is set to x_lr using one-hot-coding instead of label encoding\n",
        "ACC_test_lr = np.mean(Score_lr['test_score'])\n",
        "ACC_train_lr = np.mean(Score_lr['train_score'])\n",
        "fit_time_lr = np.mean(Score_lr['fit_time'])\n",
        "score_time_lr = np.mean(Score_lr['score_time'])\n",
        "\n",
        "##DT\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "Score_dt = cross_validate(DecisionTreeClassifier(),x,y,return_train_score=True)\n",
        "ACC_test_dt = np.mean(Score_dt['test_score'])\n",
        "ACC_train_dt = np.mean(Score_dt['train_score'])\n",
        "fit_time_dt = np.mean(Score_dt['fit_time'])\n",
        "score_time_dt = np.mean(Score_dt['score_time'])\n",
        "\n",
        "##SVM\n",
        "from sklearn.svm import SVC\n",
        "Score_svm = cross_validate(SVC(),x,y,return_train_score=True)\n",
        "ACC_test_svm = np.mean(Score_svm['test_score'])\n",
        "ACC_train_svm = np.mean(Score_svm['train_score'])\n",
        "fit_time_svm = np.mean(Score_svm['fit_time'])\n",
        "score_time_svm = np.mean(Score_svm['score_time'])\n",
        "\n",
        "##RF\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "Score_rf = cross_validate(RandomForestClassifier(),x,y,return_train_score=True)\n",
        "ACC_test_rf = np.mean(Score_rf['test_score'])\n",
        "ACC_train_rf = np.mean(Score_rf['train_score'])\n",
        "fit_time_rf = np.mean(Score_rf['fit_time'])\n",
        "score_time_rf = np.mean(Score_rf['score_time'])\n",
        "\n",
        "##NB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "Score_nb = cross_validate(GaussianNB(),x,y,return_train_score=True)\n",
        "ACC_test_nb = np.mean(Score_nb['test_score'])\n",
        "ACC_train_nb = np.mean(Score_nb['train_score'])\n",
        "fit_time_nb = np.mean(Score_nb['fit_time'])\n",
        "score_time_nb = np.mean(Score_nb['score_time'])\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'Logistic' , 'DT' , 'SVM' , 'RF', 'NB'])\n",
        "t.add_row(['Training (%)', ACC_train_lr*100, ACC_train_dt*100, ACC_train_svm*100, ACC_train_rf*100, ACC_train_nb*100])\n",
        "t.add_row(['Testing (%)', ACC_test_lr*100, ACC_test_dt*100, ACC_test_svm*100, ACC_test_rf*100, ACC_test_nb*100])\n",
        "t.add_row(['fit_time per fold', fit_time_lr, fit_time_dt, fit_time_svm, fit_time_rf, fit_time_nb])\n",
        "t.add_row(['score_time per fold', score_time_lr, score_time_dt, score_time_svm, score_time_rf, score_time_nb])\n",
        "print(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJiPgz8SADfQ",
        "colab_type": "text"
      },
      "source": [
        "**Comment on the training and testing accuracies in the table above?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSuLFMYF-snQ",
        "colab_type": "text"
      },
      "source": [
        "Let us try to use the **leave-one-out cross-validation** approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAifzonV-_NU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## compute maximum posssible cv values\n",
        "y_0 =  HR_GF[HR_GF['left'] == 0]\n",
        "y_1 =  HR_GF[HR_GF['left'] == 1]\n",
        "cv_value = int(min(y_0.shape[0], y_1.shape[0]))\n",
        "cv_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPwZyhJn_uxS",
        "colab_type": "text"
      },
      "source": [
        "This is a large number and will take alot of time cosnidering all ML techniques. And thus we will use cv value of 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL37ErM-BX5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_value = 10\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "##LR\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "Score_lr = cross_validate(LogisticRegression(),x_lr,y,return_train_score=True, cv = cv_value) ##x is set to x_lr using one-hot-coding instead of label encoding\n",
        "ACC_test_lr = np.mean(Score_lr['test_score'])\n",
        "ACC_train_lr = np.mean(Score_lr['train_score'])\n",
        "fit_time_lr = np.sum(Score_lr['fit_time'])\n",
        "score_time_lr = np.sum(Score_lr['score_time'])\n",
        "\n",
        "##DT\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "Score_dt = cross_validate(DecisionTreeClassifier(),x,y,return_train_score=True, cv = cv_value)\n",
        "ACC_test_dt = np.mean(Score_dt['test_score'])\n",
        "ACC_train_dt = np.mean(Score_dt['train_score'])\n",
        "fit_time_dt = np.sum(Score_dt['fit_time'])\n",
        "score_time_dt = np.sum(Score_dt['score_time'])\n",
        "\n",
        "##SVM\n",
        "from sklearn.svm import SVC\n",
        "Score_svm = cross_validate(SVC(),x,y,return_train_score=True, cv = cv_value)\n",
        "ACC_test_svm = np.mean(Score_svm['test_score'])\n",
        "ACC_train_svm = np.mean(Score_svm['train_score'])\n",
        "fit_time_svm = np.sum(Score_svm['fit_time'])\n",
        "score_time_svm = np.sum(Score_svm['score_time'])\n",
        "\n",
        "##RF\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "Score_rf = cross_validate(RandomForestClassifier(),x,y,return_train_score=True, cv = cv_value)\n",
        "ACC_test_rf = np.mean(Score_rf['test_score'])\n",
        "ACC_train_rf = np.mean(Score_rf['train_score'])\n",
        "fit_time_rf = np.sum(Score_rf['fit_time'])\n",
        "score_time_rf = np.sum(Score_rf['score_time'])\n",
        "\n",
        "##NB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "Score_nb = cross_validate(GaussianNB(),x,y,return_train_score=True, cv = cv_value)\n",
        "ACC_test_nb = np.mean(Score_nb['test_score'])\n",
        "ACC_train_nb = np.mean(Score_nb['train_score'])\n",
        "fit_time_nb = np.sum(Score_nb['fit_time'])\n",
        "score_time_nb = np.sum(Score_nb['score_time'])\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy', 'Logistic' , 'DT' , 'SVM' , 'RF', 'NB'])\n",
        "t.add_row(['Training (%)', ACC_train_lr*100, ACC_train_dt*100, ACC_train_svm*100, ACC_train_rf*100, ACC_train_nb*100])\n",
        "t.add_row(['Testing (%)', ACC_test_lr*100, ACC_test_dt*100, ACC_test_svm*100, ACC_test_rf*100, ACC_test_nb*100])\n",
        "t.add_row(['fit_time per fold', fit_time_lr, fit_time_dt, fit_time_svm, fit_time_rf, fit_time_nb])\n",
        "t.add_row(['score_time per fold', score_time_lr, score_time_dt, score_time_svm, score_time_rf, score_time_nb])\n",
        "print(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4OX2FXYWV62",
        "colab_type": "text"
      },
      "source": [
        "**1- Comment on the training and testing accuracies in the table above?**\n",
        "\n",
        "**2- Use KCV to tune the number of tress parameter in RF**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIgCwet8SjNR",
        "colab_type": "text"
      },
      "source": [
        "# Case #3: Recognition of Handwritten Digits\n",
        "\n",
        "In this section, we will fine tune the parameters of **RandomForest** (RF) using the **K-Fold Cross Validation** to recognize handwritten digits using . We will be using a standard dataset available through the sklearn library called \"load_digits\".$^{[1][2]}$\n",
        "\n",
        "[1] https://scikit-learn.org/stable/tutorial/basic/tutorial.html#introduction\n",
        "\n",
        "[2] https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQdZcUD-BBMi",
        "colab_type": "text"
      },
      "source": [
        "**implementation** (you may run the first few cells quickly if you have done this probem in the the previous tutorials)\n",
        "\n",
        "In the beginning, we will load the dataset as follows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thCgqt3KSpwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGRXkAwRMDWg",
        "colab_type": "text"
      },
      "source": [
        "A dataset is a dictionary-like object that holds all the data and some metadata about the data. Let us explore the content of the digits dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8qlgSoRTAhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir(digits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEbzkkNqMLZf",
        "colab_type": "text"
      },
      "source": [
        "The digits.data contains the features that will be used to classify the digits samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lw41j9WUlr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(digits.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_ZbG54iNTgV",
        "colab_type": "text"
      },
      "source": [
        "The digits.images contains the images of the digits samples. They can be viewed using the following code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsM4ZMMWXGBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.gray()\n",
        "plt.matshow(digits.images[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK1cRXeTNmwf",
        "colab_type": "text"
      },
      "source": [
        "The ground truth of the datset is stored in the digits.taget"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX5YG-S-UxiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(digits.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy6FObMY7yo2",
        "colab_type": "text"
      },
      "source": [
        "Let us use Principle Component Analysis to view the digits dataset. We will lot a projection on the 2 first principal axis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJA-IsUh7zxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "proj = pca.fit_transform(digits.data)\n",
        "plt.scatter(proj[:, 0], proj[:, 1], c=digits.target, cmap=\"Paired\")\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc0cKNwJN45-",
        "colab_type": "text"
      },
      "source": [
        "After exploring the content of the digits dataset, we will design a classified using **RF**. First, we decide the input feature vector (x) and the ground truth (y) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jSk9q-BU-1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = digits.data\n",
        "y = digits.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9KDqCdXOn3M",
        "colab_type": "text"
      },
      "source": [
        "Here we will train the **RF** model and compute the accuracies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7QAzJ0pV6Am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv_value = 5 ## default value\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "##RF\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "Score_rf = cross_validate(RandomForestClassifier(),x,y,return_train_score=True, cv = cv_value)\n",
        "ACC_test_rf = np.mean(Score_rf['test_score'])\n",
        "ACC_train_rf = np.mean(Score_rf['train_score'])\n",
        "fit_time_rf = np.sum(Score_rf['fit_time'])\n",
        "score_time_rf = np.sum(Score_rf['score_time'])\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['Accuracy','RF '])\n",
        "t.add_row(['Training (%)', ACC_train_rf*100])\n",
        "t.add_row(['Testing (%)',  ACC_test_rf*100])\n",
        "t.add_row(['fit_time (total)', fit_time_rf])\n",
        "t.add_row(['score_time (total)', score_time_rf])\n",
        "print(t)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig8JsexROuls",
        "colab_type": "text"
      },
      "source": [
        "We will then tune the number of trees in **RF**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7Ya-2R5tE1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = digits.data\n",
        "y = digits.target\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from prettytable import PrettyTable\n",
        "t = PrettyTable(['n_estimators','Accuracy of RF'])\n",
        "\n",
        "##RF (cv = 10)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "for n_trees in range(10,200,10):\n",
        "  Score_rf = cross_validate(RandomForestClassifier(n_estimators = n_trees),x,y,return_train_score=True, cv = 10)\n",
        "  ACC_test_rf = np.mean(Score_rf['test_score'])\n",
        "  t.add_row([n_trees, ACC_test_rf*100])\n",
        "\n",
        "print(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf4y6xniXMj5",
        "colab_type": "text"
      },
      "source": [
        "**1- Comment on the training and testing accuracies in the table above**\n",
        "\n",
        "**2- Check how does the number of folds (k) affect the accuracy of RF**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clLdKNnsVLSK",
        "colab_type": "text"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "**Exercise #1**\n",
        "\n",
        "**Exercise #2**"
      ]
    }
  ]
}